{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96579f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .env 파일에서 환경 변수 로드 (OPENAI_API_KEY 등)\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a045c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain의 ChatUpstage 모델 초기화\n",
    "# 환경 변수에서 OPENAI_API_KEY를 자동으로 읽어옵니다\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d25e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Retrieval Augmented Generation (RAG)은 자연어 처리(NLP) 분야에서 사용되는 기술로, 기존의 정보를 검색하여 새로운 텍스트를 생성하는 방법입니다. 이 기술은 모델이 생성하는 응답의 정확성과 신뢰성을 높이기 위해 사용됩니다.\\n\\nRAG의 작동 원리는 다음과 같습니다:\\n\\n1. **검색(Retrieval)**: 사용자가 입력한 질문이나 프롬프트에 대해 관련성이 높은 문서나 정보를 검색합니다. 이때, 일반적으로 역색인(inverted index)을 사용하여 효율적으로 검색을 수행합니다.\\n\\n2. **컨텍스트 추출(Context Extraction)**: 검색된 문서에서 질문에 가장 관련성이 높은 부분을 추출하여 모델이 생성할 때 사용할 컨텍스트를 준비합니다.\\n\\n3. **생성(Generation)**: 추출된 컨텍스트를 기반으로 모델이 새로운 텍스트를 생성합니다. 이때, 모델은 컨텍스트를 참고하여 더 정확하고 관련성 높은 응답을 생성할 수 있습니다.\\n\\nRAG는 특히 대규모의 정적 문서나 데이터베이스에서 정보를 검색하여 사용해야 하는 경우에 유용합니다. 이를 통해 모델은 더 많은 정보를 바탕으로 응답을 생성할 수 있으며, 이는 모델의 성능을 향상시키는 데 도움이 됩니다. 또한, RAG는 모델의 학습 데이터를 업데이트하지 않고도 새로운 정보를 반영할 수 있어 유연성이 높습니다.\\n\\nRAG는 검색 엔진, 지식 기반 시스템, 고객 서비스 챗봇 등 다양한 분야에서 활용될 수 있습니다. 예를 들어, 의료 분야에서 환자의 증상을 입력받아 관련 의학 논문을 검색하여 진단에 도움을 줄 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 327, 'prompt_tokens': 21, 'total_tokens': 348, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'solar-mini-250422', 'system_fingerprint': None, 'id': '97de38ed-362c-44f5-bcfc-11461b11bcdb', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--b878be61-c681-4e99-a74b-c70ffa3f4062-0', usage_metadata={'input_tokens': 21, 'output_tokens': 327, 'total_tokens': 348, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM에 질문을 보내고 응답 받기 (전체 AIMessage 객체 반환)\n",
    "llm.invoke(\"Retrieval Augmented Generation는 무엇인가요??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90954f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Retrieval Augmented Generation(RAG)는 자연어 처리(NLP) 분야에서 사용되는 기술로, 기계가 생성한 응답의 정확성과 관련성을 향상시키기 위한 방법입니다. 이 기술은 두 가지 주요 단계로 구성됩니다: 검색(Retrieval)과 생성(Generation).\\n\\n1. **검색(Retrieval)**: 먼저, 주어진 질의나 입력에 대해 관련 있는 지식을 데이터베이스나 인덱스에서 검색합니다. 이때, 검색된 정보는 주로 문서, 데이터베이스 레코드, 또는 기타 구조화된 데이터 형태일 수 있습니다. 검색 과정에서는 벡터 공간 모델링, 키워드 매칭, 또는 기타 검색 알고리즘을 사용하여 가장 관련성이 높은 정보를 찾습니다.\\n\\n2. **생성(Generation)**: 검색된 정보를 기반으로, 이를 활용하여 최종적인 응답이나 텍스트를 생성합니다. 생성 단계에서는 다양한 NLP 모델(예: Transformer 기반 모델)을 사용하여 검색된 정보를 적절히 조합하고, 질문에 맞는 자연스럽고 의미 있는 응답을 만들어냅니다.\\n\\nRAG의 주요 장점은 기존의 단순한 데이터 검색이나 기계 생성 응답의 한계를 극복하여, 더 정확하고 관련성 높은 정보를 기반으로 응답을 생성할 수 있다는 점입니다. 이를 통해 검색 엔진의 정보 제공 정확성을 높이고, 챗봇이나 가상 어시스턴트의 응답 품질을 개선할 수 있습니다. RAG는 특히 대규모 문서나 데이터베이스에서 특정 정보를 빠르게 찾아내야 하는 응용 분야에서 유용하게 사용됩니다.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM 응답에서 텍스트 내용만 추출하기\n",
    "# .content 속성을 사용하면 AIMessage에서 실제 텍스트만 가져올 수 있습니다\n",
    "llm_response = llm.invoke(\"Retrieval Augmented Generation는 무엇인가요??\")\n",
    "\n",
    "llm_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f5c88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-application-with-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
